{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database.data import Data\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from models.scoring_metrics import get_all_metrics, scoring_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating DATA object\n",
    "ptb_binary_SVM = Data(database = 'ptbdb', denoise_method='DWT', estimation_method = 'SVM', train_splits=None, binary = True, parameterisation = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering Database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [00:58<00:00,  9.31it/s]\n",
      "100%|██████████| 221/221 [00:01<00:00, 132.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoising signals through Discrete Wavelet Transform\n",
      "normalising signals\n",
      "calculating time domain parameters\n",
      "calculating frequency domain parameters\n",
      "calculating non linear domain parameters\n",
      "selecting 4 most important features\n",
      "Selected features for channel 1:\n",
      "['rr_amps', 'mean', 'lf', 'age']\n",
      "Selected features for channel 2:\n",
      "['rr_amps', 'shannon_en', 'sd2', 'age']\n",
      "Selected features for channel 3:\n",
      "['rr_std', 'sd1', 'sd2', 'age']\n",
      "Selected features for channel 4:\n",
      "['rr_amps', 'std', 'sd_ratio', 'age']\n",
      "Selected features for channel 5:\n",
      "['skews', 'sd1', 'sd2', 'age']\n",
      "Selected features for channel 6:\n",
      "['RMSSD', 'mean', 'sd2', 'age']\n"
     ]
    }
   ],
   "source": [
    "ptb_binary_SVM.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = ptb_binary_SVM.input_data\n",
    "labels = ptb_binary_SVM.labels\n",
    "\n",
    "labels_encoded = []\n",
    "\n",
    "for i in range(6):\n",
    "    encoded = [0 if label == 'Unhealthy' else 1 for label in labels[i]]\n",
    "    labels_encoded.append(np.array(encoded))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this for average channel scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameter grid to test\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale']#including 'auto' aswell takes forever\n",
    "}\n",
    "\n",
    "y_tests_list = []\n",
    "probs_list = []\n",
    "metrics = []\n",
    "thresholds_list = []\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    #define classifier\n",
    "    svc = SVC(class_weight='balanced', probability = True)\n",
    "\n",
    "    #find the best set of hyperparameters for each channel, tuned on the desired scoring function\n",
    "    best_svc = tune_hyperparams(input_data[i], labels_encoded[i], param_grid, svc, scorer='balanced_accuracy')\n",
    "\n",
    "    #perform 3 way skfold to get scores for each channel as well as their probabilities\n",
    "    n_splits = 3\n",
    "    all_score_metrics, thresholds, probabilities, y_tests, test_indices = perform_skfold(input_data[i], labels_encoded[i], n_splits, best_svc, get_probabilities=True)\n",
    "\n",
    "    #monitoring scores for each channel\n",
    "    metrics.append(all_score_metrics)\n",
    "\n",
    "    #calculating average threshold from all splits\n",
    "    threshold = np.mean(thresholds)\n",
    "\n",
    "    #reconstructing calculated probabilities so can optimise over all channels\n",
    "    reconstructed_probs = reconstruct_probs(probabilities, test_indices, ptb_binary_SVM.nan_indices[i], ptb_binary_SVM.allowed_patients.count_patients(), n_splits)\n",
    "\n",
    "    #need for ROC curve and confusion matrix later\n",
    "    probs_list.append(reconstructed_probs)\n",
    "    y_tests_list.append(y_tests)\n",
    "    thresholds_list.append(threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('F1 score', 0.3089130113720278), ('Objective score', 0.35734274941700206), ('Bal Acc', 0.4703454715219421), ('Accuracy', 0.488966588966589), ('precision', 0.24318435188000406), ('recall', 0.4365079365079365)])\n",
      "dict_items([('F1 score', 0.514484126984127), ('Objective score', 0.5717442400594575), ('Bal Acc', 0.7053511705685619), ('Accuracy', 0.6986167932982661), ('precision', 0.40554363966342183), ('recall', 0.717948717948718)])\n",
      "dict_items([('F1 score', 0.5198830409356724), ('Objective score', 0.5820458342826763), ('Bal Acc', 0.7270923520923521), ('Accuracy', 0.6876310272536688), ('precision', 0.3888076673164392), ('recall', 0.7954545454545455)])\n",
      "dict_items([('F1 score', 0.4721254355400697), ('Objective score', 0.5310047255152285), ('Bal Acc', 0.6683897354572655), ('Accuracy', 0.7055555555555556), ('precision', 0.4005291005291005), ('recall', 0.6007326007326007)])\n",
      "dict_items([('F1 score', 0.5125432629192027), ('Objective score', 0.5742564745196325), ('Bal Acc', 0.7182539682539684), ('Accuracy', 0.6894003978402955), ('precision', 0.38578431372549016), ('recall', 0.7698412698412699)])\n",
      "dict_items([('F1 score', 0.5496678667410375), ('Objective score', 0.6053036529624196), ('Bal Acc', 0.735120487478978), ('Accuracy', 0.7374158618671349), ('precision', 0.4420512820512821), ('recall', 0.7301587301587301)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for i in range(6):\n",
    "    print(metrics[i].items())\n",
    "    #print(classification_report(y_tests[i], y_preds[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECG-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
