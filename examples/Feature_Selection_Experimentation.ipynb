{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook exists too experiment with the different methods seen to perform feature selection. Methods include:\n",
    "- Statistical Measures\n",
    "- PCA\n",
    "- Wrapper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 549/549 [00:27<00:00, 19.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 202/202 [00:02<00:00, 88.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unhealthy lf_power: mean:0.002246771347577131, std: 0.005716348092590171\n",
      "Healthy lf_power: mean:0.001986485016994376, std:0.004750847001099235\n",
      "Unhealthy hf_power: mean:0.004085063574954664, std: 0.00801349983605936\n",
      "Healthy hf_power: mean:0.0029768474608233256, std:0.006931241434845449\n",
      "Unhealthy ratio of power bands: mean:2.1906510706529017, std: 4.5578331544128385\n",
      "Healthy ratio of power bands: mean:3.6707058173199845, std:6.545749052455982\n"
     ]
    }
   ],
   "source": [
    "%run \"Parameter_Estimation.ipynb\" #allowing access to parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_state = allowed_patients.get_diagnoses()\n",
    "\n",
    "encoded_health_state = [True if label == 'Unhealthy' else False for label in health_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation \n",
    "#### pmcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter rr_mean and parameter rr_std are significantly correlated, p = 4.062395325115764e-08, corr = 0.3743340369120984\n",
      "parameter rr_mean and parameter RMSSD are significantly correlated, p = 2.2987696809200955e-06, corr = 0.32539154949177745\n",
      "parameter rr_mean and parameter pNN50 are significantly correlated, p = 0.0007941729849659782, corr = 0.2342059568006114\n",
      "parameter rr_mean and parameter std are significantly correlated, p = 5.435433259682619e-10, corr = -0.4189936627892915\n",
      "parameter rr_mean and parameter kurtosis are significantly correlated, p = 9.662209716789082e-10, corr = 0.4134062412423312\n",
      "parameter rr_mean and parameter shannon_en are significantly correlated, p = 7.227845542211822e-05, corr = -0.275519796590391\n",
      "parameter rr_std and parameter RMSSD are significantly correlated, p = 2.4389447379852025e-120, corr = 0.9666972499757714\n",
      "parameter rr_std and parameter pNN50 are significantly correlated, p = 5.386345605631653e-40, corr = 0.7644747575824683\n",
      "parameter rr_std and parameter std are significantly correlated, p = 6.756149847031246e-05, corr = -0.276590742373634\n",
      "parameter rr_std and parameter hf are significantly correlated, p = 0.00014266798261788102, corr = 0.26447351754367227\n",
      "parameter rr_std and parameter lf are significantly correlated, p = 1.6771316671617605e-05, corr = 0.2977804976656451\n",
      "parameter RMSSD and parameter pNN50 are significantly correlated, p = 1.2179799228623573e-47, corr = 0.8070435178863411\n",
      "parameter RMSSD and parameter std are significantly correlated, p = 0.0012106074791253998, corr = -0.22615607113850433\n",
      "parameter RMSSD and parameter hf are significantly correlated, p = 1.0092616325582444e-05, corr = 0.30510501542674523\n",
      "parameter RMSSD and parameter lf are significantly correlated, p = 2.780638674778057e-05, corr = 0.2902856486376234\n",
      "parameter RMSSD and parameter power_ratio are significantly correlated, p = 0.024235064499717556, corr = -0.1585272769588532\n",
      "parameter pNN50 and parameter std are significantly correlated, p = 0.01041708543651565, corr = -0.17988201054804487\n",
      "parameter pNN50 and parameter kurtosis are significantly correlated, p = 0.03447070952403093, corr = 0.1488710536194099\n",
      "parameter pNN50 and parameter hf are significantly correlated, p = 2.534683082792181e-07, corr = 0.35314947656708245\n",
      "parameter pNN50 and parameter lf are significantly correlated, p = 0.0025495783889869597, corr = 0.21121354493404018\n",
      "parameter pNN50 and parameter power_ratio are significantly correlated, p = 0.009410347537714138, corr = -0.18230610271943834\n",
      "parameter mean and parameter std are significantly correlated, p = 0.019919430084018704, corr = 0.16369726894714084\n",
      "parameter mean and parameter skews are significantly correlated, p = 3.796863469782119e-68, corr = -0.8845055899985096\n",
      "parameter mean and parameter kurtosis are significantly correlated, p = 4.376791135494448e-14, corr = 0.4984752388629467\n",
      "parameter mean and parameter shannon_en are significantly correlated, p = 8.826812256245589e-06, corr = -0.3070053008880701\n",
      "parameter std and parameter kurtosis are significantly correlated, p = 1.9088386029275377e-15, corr = -0.5209070990022113\n",
      "parameter std and parameter shannon_en are significantly correlated, p = 1.1356739440645467e-22, corr = 0.6180618560802469\n",
      "parameter skews and parameter kurtosis are significantly correlated, p = 1.6088608137805098e-29, corr = -0.6867444357352283\n",
      "parameter skews and parameter shannon_en are significantly correlated, p = 7.481938977747396e-13, corr = 0.4766246011434559\n",
      "parameter kurtosis and parameter shannon_en are significantly correlated, p = 1.943722451411589e-33, corr = -0.7190134909825566\n",
      "parameter hf and parameter lf are significantly correlated, p = 7.341844920106012e-18, corr = 0.557053584403986\n",
      "parameter hf and parameter power_ratio are significantly correlated, p = 0.007359606816184616, corr = -0.1880541027603165\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import itertools\n",
    "\n",
    "for key1, key2 in itertools.combinations(params.keys(), 2):\n",
    "    corr, p_value = pearsonr(params[key1], params[key2])\n",
    "    if p_value < 0.05:\n",
    "        print(f\"parameter {key1} and parameter {key2} are significantly correlated, p = {p_value}, corr = {corr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wilcoxon \n",
    "compare the medians of two related samples or to compare repeated measurements of the same sample under different conditions. Should be used to test wether a parameter has provided a significant difference to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare above results with papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "- loses the knowledge of features, less intuitive\n",
    "- will experiment with it anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array\n",
    "X = np.zeros((no_patients, 4))#need no. samples as rows, no. features as columns for machine learning analysis\n",
    "\n",
    "# Populate the array with values from the dictionary\n",
    "X[:, 0] = params['rr_mean']\n",
    "X[:, 1] = params['kurtosis']\n",
    "X[:, 2] = params['RMSSD']\n",
    "X[:, 3] = params['shannon_en']\n",
    "    \n",
    "#standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#set desired number of principle components\n",
    "num_components = 2\n",
    "\n",
    "#using sklearn PCA\n",
    "pca = PCA(n_components=num_components)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy']\n",
      "Accuracy: 0.6885245901639344\n"
     ]
    }
   ],
   "source": [
    "#using principle components to do ML\n",
    "\n",
    "#splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, health_state, test_size=0.3)\n",
    "\n",
    "#init and train model, using radial basis functions\n",
    "svm_classifier = SVC(kernel='rbf', gamma='scale')  #'scale' normalises data, prevents overfitting\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "#evaluating accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper Methods:\n",
    "\n",
    "These methods do feature selection whilst using the model\n",
    "\n",
    " - Forward Selection: Features are sequentially added to the model, starting with an empty set and adding the feature that improves model performance the most at each step.\n",
    " - Backward Elimination: Features are sequentially removed from the model, starting with the full set of features and removing the feature that decreases model performance the least at each step.\n",
    " - Recursive Feature Elimination (RFE): Features are recursively pruned based on the importance assigned to them by the model. Less important features are eliminated iteratively until the desired number of features is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=SVC(kernel=&#x27;linear&#x27;), n_features_to_select=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=SVC(kernel=&#x27;linear&#x27;), n_features_to_select=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=SVC(kernel='linear'), n_features_to_select=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# initializing parameter array\n",
    "X = np.zeros((no_patients, 3))#need no. samples as rows, no. features as columns for machine learning analysis\n",
    "X[:, 0] = params['rr_mean']\n",
    "X[:, 1] = params['kurtosis']\n",
    "X[:, 2] = params['shannon_en']\n",
    "#X[:, 3] = params['pNN50']\n",
    "\n",
    "#splitting data into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, health_state, test_size=0.3)\n",
    "\n",
    "#initialise SVM -- have to use a linear kernel??\n",
    "svm = SVC(kernel=\"linear\")\n",
    "\n",
    "#initialize RFE with the SVM model and desired number of feauters\n",
    "rfe = RFE(estimator=svm, n_features_to_select=1)\n",
    "\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: [False False  True]\n",
      "Feature ranking: [3 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected features:\", rfe.support_)\n",
    "print(\"Feature ranking:\", rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with selected features: 0.6721311475409836\n"
     ]
    }
   ],
   "source": [
    "# transform the dataset to include only the selected features\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# train the SVM on the selected features\n",
    "svm.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm.predict(X_test_rfe)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy with selected features:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward/Backward Elimination\n",
    "\n",
    "May be slower than RFE but does not need to have coefficients i.e. a linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector \n",
    "\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "SFS_forward = SequentialFeatureSelector(estimator=svm_rbf, tol = 5)\n",
    "\n",
    "SFS_forward.fit(X_train, y_train)\n",
    "\n",
    "SFS_forward.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SFS_backward = SequentialFeatureSelector(estimator=svm_rbf, tol=-5, direction='backward')\n",
    "\n",
    "SFS_backward.fit(X_train, y_train)\n",
    "\n",
    "SFS_forward.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these agree only first one should be kept but disagrees with RFE???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded Methods:\n",
    "\n",
    "Also done whilst using the model\n",
    "\n",
    "- Regularization: Techniques like LASSO (L1 regularization) and Ridge (L2 regularization) penalize the magnitude of feature coefficients, forcing less important features to have coefficients close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LASSO/Ridge Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#changing health_state to binary for use in regression\n",
    "binary_health_state = [1 if label == 'Unhealthy' else 0 for label in health_state]\n",
    "\n",
    "#splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, binary_health_state, test_size=0.3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "#create and fit regression models\n",
    "lasso_alpha = 0.1  # Regularization strength (hyperparameter)\n",
    "lasso = Lasso(alpha=lasso_alpha)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "ridge_alpha = 0.1 \n",
    "ridge = Ridge(alpha=ridge_alpha)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "#use the trained models for prediction\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "y_pred_ridge = ridge.predict(X_test_scaled)\n",
    "y_pred_lasso = lasso.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
