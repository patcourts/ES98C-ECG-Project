{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 549/549 [01:22<00:00,  6.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 221/221 [00:01<00:00, 158.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Time Domain Features\n",
      "Calculating Frequency Domain Features\n",
      "Calculating Non-Linear Domain Features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n",
      "<ipython-input-1-b73415202eb2>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log((_phi(m + 1)) / (_phi(m)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 17)\n",
      "dict_keys(['rr_amps', 'hf', 'shannon_en', 'age'])\n",
      "dict_keys(['lf', 'total_power', 'shannon_en', 'age'])\n",
      "dict_keys(['rr_amps', 'kurtosis', 'shannon_en', 'age'])\n",
      "dict_keys(['rr_std', 'lf', 'total_power', 'age'])\n",
      "dict_keys(['rr_amps', 'std', 'skews', 'age'])\n",
      "dict_keys(['rr_std', 'hf', 'lf', 'age'])\n"
     ]
    }
   ],
   "source": [
    "%run \"Feature_Selection.ipynb\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_params = [['kurtosis', 'sd_ratio', 'lf'], ['sd_ratio_outliers_removed', 'shannon_en', 'pNN50'], ['pNN50', 'shannon_en', 'sd_ratio_outliers_removed'], ['pNN50', 'lf', 'sd_ratio_outliers_removed'], ['lf', 'pNN50', 'shannon_en'], ['lf', 'shannon_en', 'hf']]\n",
    "        \n",
    "# selected_params = {}\n",
    "# for i in range(no_channels):\n",
    "#     selected_params[i] = {}  # Initialize as an empty dictionary\n",
    "#     for param in my_params[i]:\n",
    "#         selected_params[i][param] = params[param][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_state = np.array(allowed_patients.get_diagnoses())\n",
    "\n",
    "encoded_health_state = [1 if label == 'Unhealthy' else -1 for label in health_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_av_confusion_matrix(y_test, y_pred):\n",
    "    av_confusion_mat = np.zeros(shape = (len(y_test), 2, 2))\n",
    "    for i in range(0, len(y_test)):\n",
    "        av_confusion_mat[i] = confusion_matrix(y_test[i], y_pred[i])\n",
    "    return np.mean(av_confusion_mat, axis=0)\n",
    "\n",
    "def objective_score(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    change to incorporate balanced accuracy \n",
    "    \"\"\"\n",
    "    balanced_acc = get_balanced_accuracy(y_test, y_pred)\n",
    "    specificity = get_specificity(y_test, y_pred)\n",
    "    f1 = get_f1_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    return f1*0.7 + balanced_acc*0.3\n",
    "\n",
    "def convert_multi_dict_to_array1(params_dict, nan_indices):\n",
    "    no_features = len(params_dict[0])\n",
    "    params_list = []\n",
    "    for j in range(0, no_channels):\n",
    "        params_array = np.zeros((len(health_state[nan_indices[j]]), no_features))\n",
    "        for i, values in enumerate(params_dict[j].values()):\n",
    "            params_array[:, i] = values\n",
    "        params_list.append(params_array)\n",
    "    return params_list, no_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "First convert the dictionary containing the parameters to use for each channel into an array of suitable shape for svm models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(selected_params[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_params_array, no_features = convert_multi_dict_to_array1(selected_params, nan_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparams(params, health_state, param_grid, scorer='balanced_accuracy'):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(params, health_state, test_size=0.3, stratify=health_state)\n",
    "    \n",
    "    #initialise classifier\n",
    "    svc = SVC(class_weight='balanced', probability = True)\n",
    "\n",
    "    # perform grid search\n",
    "    grid_search = GridSearchCV(svc, param_grid, cv=3, scoring=scorer)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are optimizing the hyperparameters that are used to train the model by perfroma grid search over the ``param_grid`` dictionary. The hyperparameters are chosen based on their optimisation of the manually defined ``scoring_function``. This takes a while as it has to perform a search over all the possible hyperparameters for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameter grid to test\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale']#including 'auto' aswell takes forever\n",
    "}\n",
    "\n",
    "\n",
    "best_estimators = []\n",
    "for i in range(0, no_channels):\n",
    "    best_estimators.append(tune_hyperparams(selected_params_array[i], health_state[nan_indices[i]], param_grid, scoring_function))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVC(C=10, class_weight='balanced', probability=True), SVC(C=0.1, class_weight='balanced', probability=True), SVC(C=10, class_weight='balanced', probability=True), SVC(C=10, class_weight='balanced', probability=True), SVC(C=10, class_weight='balanced', probability=True), SVC(C=1, class_weight='balanced', probability=True)]\n"
     ]
    }
   ],
   "source": [
    "print(best_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the best set of hyperparameters we perform a 3 fold stratisfied split to investigate the accuracy. Firstly we can investigate the average accuracy of each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skfold_with_probabilities(params, health_state, n_splits, best_estimator, scorer):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42) #can do repeated skf for better validation\n",
    "    \n",
    "    probabilities = []\n",
    "    sample_percentages = []\n",
    "    y_tests = []\n",
    "    balanced_accuracy = []\n",
    "    score_func = []\n",
    "    test_indices = []\n",
    "    for train_index, test_index in skf.split(params, health_state):\n",
    "        #getting test and train data sets\n",
    "        X_train, X_test = params[train_index], params[test_index]\n",
    "        y_train, y_test = health_state[train_index], health_state[test_index]\n",
    "        \n",
    "        \n",
    "        #calculating percentage of healthy in training data\n",
    "        sample_percentages.append(np.mean(y_train == 'Healthy')) #how is threshold measured??? health_state[train_index]??\n",
    "        \n",
    "        #fitting data on previously calculated best estimator\n",
    "        best_estimator.fit(X_train, y_train)\n",
    "        \n",
    "        #evaluating model\n",
    "        y_pred = best_estimator.predict(X_test)\n",
    "        score_func.append(scorer(best_estimator, X_train, y_test))\n",
    "        balanced_accuracy.append(get_balanced_accuracy(y_test, y_pred))\n",
    "        \n",
    "        #for evaluation of model later\n",
    "        probabilities.append(best_estimator.predict_proba(X_test))\n",
    "        y_tests.append(y_test)\n",
    "        \n",
    "        #for reconstruction of full patient data\n",
    "        test_indices.append(test_index)\n",
    "\n",
    "    return np.mean(np.array(score_func)), np.mean(np.array(balanced_accuracy)), probabilities, sample_percentages, y_tests, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_accuracy = []\n",
    "balanced_accuracy = []\n",
    "n_splits=3\n",
    "\n",
    "probs = []\n",
    "thresholds = []\n",
    "y_tests = []\n",
    "test_indices = []\n",
    "\n",
    "for i in range(0, no_channels):\n",
    "    score_acc, bal_acc, prob, threshold, y_test, test_indice = skfold_with_probabilities(selected_params_array[i], health_state[nan_indices[i]], n_splits, best_estimators[i], scoring_function)\n",
    "    score_accuracy.append(score_acc)\n",
    "    balanced_accuracy.append(bal_acc)\n",
    "    probs.append(prob)\n",
    "    thresholds.append(threshold)\n",
    "    y_tests.append(y_test)\n",
    "    test_indices.append(test_indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success Metric</th>\n",
       "      <th>Channel 1</th>\n",
       "      <th>Channel 2</th>\n",
       "      <th>Channel 3</th>\n",
       "      <th>Channel 4</th>\n",
       "      <th>Channel 5</th>\n",
       "      <th>Channel 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Objective Score</td>\n",
       "      <td>0.7239246218080847</td>\n",
       "      <td>0.7352390132389237</td>\n",
       "      <td>0.7632646339168078</td>\n",
       "      <td>0.7222567851256564</td>\n",
       "      <td>0.7236904638628777</td>\n",
       "      <td>0.7387254249361167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.6901960784313724</td>\n",
       "      <td>0.6907469342251952</td>\n",
       "      <td>0.6957070707070706</td>\n",
       "      <td>0.6530159633767404</td>\n",
       "      <td>0.7004409171075837</td>\n",
       "      <td>0.6987363789250581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Success Metric           Channel 1           Channel 2  \\\n",
       "0    Objective Score  0.7239246218080847  0.7352390132389237   \n",
       "1  Balanced Accuracy  0.6901960784313724  0.6907469342251952   \n",
       "\n",
       "            Channel 3           Channel 4           Channel 5  \\\n",
       "0  0.7632646339168078  0.7222567851256564  0.7236904638628777   \n",
       "1  0.6957070707070706  0.6530159633767404  0.7004409171075837   \n",
       "\n",
       "            Channel 6  \n",
       "0  0.7387254249361167  \n",
       "1  0.6987363789250581  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#presenting results as pandas df\n",
    "data = {\n",
    "    'Success Metric': ['Objective Score', 'Balanced Accuracy'],\n",
    "    'Channel 1': [f'{score_accuracy[0]}', f'{balanced_accuracy[0]}'],\n",
    "    'Channel 2': [f'{score_accuracy[1]}', f'{balanced_accuracy[1]}'],\n",
    "    'Channel 3': [f'{score_accuracy[2]}', f'{balanced_accuracy[2]}'],\n",
    "    'Channel 4': [f'{score_accuracy[3]}', f'{balanced_accuracy[3]}'],\n",
    "    'Channel 5': [f'{score_accuracy[4]}', f'{balanced_accuracy[4]}'],\n",
    "    'Channel 6': [f'{score_accuracy[5]}', f'{balanced_accuracy[5]}'],\n",
    "    \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then can average the probabilities for each channel to get an overall accuracy for the method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the arrays are now all different length with different patients' date having been discarded the below no longer works. will try to recreate each patients data from the array indices and test indices given by sklearn so that probabilities can be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_probs(probs, test_indices, nan_indices):\n",
    "    reconstructed_probs = np.zeros(no_patients)\n",
    "    reconstructed_probs[~nan_indices] = np.nan\n",
    "    allowed_indices = np.arange(0, no_patients)[nan_indices]\n",
    "\n",
    "    for z in range(0, n_splits):\n",
    "        for i, indice in enumerate(test_indices[z]):\n",
    "            reconstructed_probs[allowed_indices[indice]] = probs[z][i][0]\n",
    "            \n",
    "\n",
    "    return reconstructed_probs\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_probs = []\n",
    "for i in range(0, no_channels):\n",
    "    reconstructed_prob = reconstruct_probs(probs[i], test_indices[i], nan_indices[i])\n",
    "    reconstructed_probs.append(reconstructed_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-5ab2b991886d>:27: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(average_probs, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# def average_probabilities(probs, n_splits, channels):\n",
    "#     average_probs = []\n",
    "#     for i in range(0, n_splits):\n",
    "#         probas = []\n",
    "#         for channel in channels:\n",
    "#             probas.append(probs[channel][i])\n",
    "#         average_probs.append(np.mean(probas, axis=0)[:, 0])\n",
    "#     return average_probs\n",
    "\n",
    "# def manual_y_pred(average_probs, n_splits, thresholds):\n",
    "#     manual_y_pred = []\n",
    "#     for i in range(0, n_splits):\n",
    "#         manual_predict = []\n",
    "#         for j in range(0, len(average_probs[i])):\n",
    "#             if average_probs[i][j] > thresholds[0][i]:\n",
    "#                 manual_predict.append('Healthy')\n",
    "#             else:\n",
    "#                 manual_predict.append('Unhealthy')\n",
    "#         manual_y_pred.append(manual_predict)\n",
    "#     return manual_y_pred\n",
    "\n",
    "def average_probabilities(probs, channels):\n",
    "    average_probs = []\n",
    "    for channel in channels:\n",
    "        average_probs.append(probs[channel])\n",
    "\n",
    "    return np.nanmean(average_probs, axis=0)\n",
    "    \n",
    "def manual_y_predict(average_probs, threshold):\n",
    "    manual_y_pred = np.empty(len(average_probs), dtype=object)\n",
    "    for j in range(0, len(average_probs)):\n",
    "        if average_probs[j] > 0.3:\n",
    "            manual_y_pred[j] = 'Healthy'\n",
    "        elif average_probs[j] <= 0.3:\n",
    "            manual_y_pred[j] = 'Unhealthy'\n",
    "        elif average_probs[j] is None:\n",
    "            manual_y_pred[j] = np.nan\n",
    "    return manual_y_pred\n",
    "\n",
    "\n",
    "\n",
    "channel_indices_list = [0, 1, 2, 3, 4, 5]\n",
    "all_combinations = []\n",
    "for r in range(1, len(probs) + 1):\n",
    "    combination = list(itertools.combinations(channel_indices_list, r))\n",
    "    all_combinations.extend(combination)\n",
    "    \n",
    "#print(thresholds)\n",
    "best_score = 0\n",
    "best_channel_indices = []\n",
    "for combo in all_combinations:\n",
    "        \n",
    "        # Use combo to get channel indices\n",
    "        selected_channel_indices = [channel_indices_list[i] for i in combo]\n",
    "        \n",
    "        #print(selected_channel_indices)\n",
    "        #no longer have any splits\n",
    "        #combo_probs = average_probabilities(probs, n_splits, selected_channel_indices)\n",
    "        #manual_pred = manual_y_pred(combo_probs, n_splits, thresholds)\n",
    "        \n",
    "        combo_probs = average_probabilities(reconstructed_probs, selected_channel_indices)\n",
    "        manual_pred = manual_y_predict(combo_probs, thresholds)\n",
    "\n",
    "\n",
    "        #dont have any channels, is all combined into one\n",
    "        score = objective_score(health_state, manual_pred)\n",
    "            \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_channel_indices = selected_channel_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8448497069372758\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "print(best_score)\n",
    "print(best_channel_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rr_amps', 'hf', 'shannon_en', 'age'])\n",
      "dict_keys(['lf', 'total_power', 'shannon_en', 'age'])\n",
      "dict_keys(['rr_amps', 'kurtosis', 'shannon_en', 'age'])\n",
      "dict_keys(['rr_std', 'lf', 'total_power', 'age'])\n",
      "dict_keys(['rr_amps', 'std', 'skews', 'age'])\n",
      "dict_keys(['rr_std', 'hf', 'lf', 'age'])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, no_channels):\n",
    "    print(selected_params[i].keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
