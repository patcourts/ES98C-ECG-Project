{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes access to denoised, detrended signals and calculates the appropriate parameters for the signal.\n",
    "This notebook assumes access to detrended, denoised signals and calculates various parameters (and uncertainties) from these signals.The parameters estimated within this notebook are split into three different types: time-domain, frequency-domain and non-linear:\n",
    "\n",
    "Time domain:\n",
    " - mean RR intervals\n",
    " - std RR intervals \n",
    " - mean amplitude\n",
    " - RMSSD of differences between successive RR intervals \n",
    " - pNN50 (%) NN50 divided by total number of RR (NN50 is the number of sucessive RR intervals that differ by more than 50ms) \n",
    " \n",
    " \n",
    "Frequency Domain:\n",
    "- absolute power of LF (0.04 - 0.15 Hz) band\n",
    "- absolute power of HF (0.15 to 0.4Hz) band\n",
    "- LF/HF ratio\n",
    "- Total power (0-0.4 Hz)\n",
    "\n",
    "Non-linear:\n",
    "- Fractal dimension of dynamic attractor of signal\n",
    "- std of poincare\n",
    "- Shannon entropy\n",
    "- recurrence rate\n",
    "- detrended fluctuation analysis\n",
    "- correlation dimension\n",
    "- sample entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 549/549 [00:15<00:00, 35.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [00:03<00:00, 54.17it/s]\n"
     ]
    }
   ],
   "source": [
    "%run \"Data_PreProcessing.ipynb\" #allowing access to the filtered database with preprocessed signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks #for peak finding\n",
    "from scipy.stats import skew, kurtosis #for signal measures\n",
    "from pyhrv.hrv import hrv #for some automatic feature extraction\n",
    "import biosppy #for rpeak calculation\n",
    "import pyhrv.time_domain as td #for calculation of heart rate\n",
    "from scipy.signal import welch #for frequency band\n",
    "from scipy.interpolate import interp1d #for interpolation of signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_averages(parameter, health_state):\n",
    "    \"\"\"\n",
    "    calculates healthy and unhealthy means and std of parameter for easy comparisson\n",
    "    returns np.array containing: healthy mean, healthy std, unhealthy mean, unhealhty std\n",
    "    \"\"\"\n",
    "    encoded_health_state = [True if label == 'Unhealthy' else False for label in health_state]\n",
    "    \n",
    "    unhealthy_param = parameter[encoded_health_state]\n",
    "    healthy_param = parameter[~np.array(encoded_health_state)]\n",
    "    \n",
    "    unhealthy_param_av = np.mean(unhealthy_param)\n",
    "    unhealthy_param_std = np.std(unhealthy_param)\n",
    "    \n",
    "    healthy_param_av = np.mean(healthy_param)\n",
    "    healthy_param_std = np.std(healthy_param)\n",
    "    \n",
    "    return np.array([healthy_param_av, healthy_param_std, unhealthy_param_av, unhealthy_param_std])\n",
    "\n",
    "def print_averages(parameter, parameter_name):\n",
    "    health_state = allowed_patients.get_diagnoses()\n",
    "    \n",
    "    means = parameter_averages(parameter, health_state)\n",
    "    \n",
    "    print(f\"Unhealthy {parameter_name}: mean:{means[2]}, std: {means[3]}\")\n",
    "    print(f\"Healthy {parameter_name}: mean:{means[0]}, std:{means[1]}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers in rr removed automatically in biosppy\n",
    "def outliers_indices_z_score(data, threshold=2):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    z_scores = [(x - mean) / std for x in data]\n",
    "    indices = np.argwhere([abs(z)<threshold for z in z_scores])\n",
    "    return indices\n",
    "\n",
    "def get_peaks(signal, remove_outliers=False):\n",
    "    peaks, _ = find_peaks(signal, distance = 600)\n",
    "    peak_to_peak = peaks[1:-1]\n",
    "    \n",
    "    if remove_outliers:\n",
    "        amp = signal[peak_to_peak]\n",
    "        amp_outlier_indices = outliers_indices_z_score(amp)\n",
    "        peak_to_peaks = peak_to_peak[amp_outlier_indices]\n",
    "        \n",
    "    else:\n",
    "        peak_to_peaks = peak_to_peak\n",
    "        \n",
    "    return peak_to_peaks\n",
    "        \n",
    "\n",
    "def get_rri(signal, remove_outliers=False):\n",
    "    t, filtered_signal, rpeaks = biosppy.signals.ecg.ecg(signal, show=False)[:3]\n",
    "    \n",
    "    # calculates rr intervals\n",
    "    rri = np.diff(rpeaks)\n",
    "\n",
    "    #removal of outliers\n",
    "    if remove_outliers:\n",
    "        rri_outlier_indices = outliers_indices_z_score(rri).reshape(-1)\n",
    "        rr_intervals = rri[rri_outlier_indices]\n",
    "        \n",
    "    else:\n",
    "        rr_intervals = rri\n",
    "        \n",
    "    return rr_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-calculation of rpeaks to save time \n",
    "\n",
    "# Get R-peaks series using biosppy\n",
    "r_peak_list_all_channels = []\n",
    "for i, signal in enumerate(denoised_signals):\n",
    "    r_peak_list = []\n",
    "    for j in range(0, len(signal)):\n",
    "        t, filtered_signal, rpeaks = biosppy.signals.ecg.ecg(signal[j], show=False)[:3]\n",
    "        r_peak_list.append(rpeaks)\n",
    "    r_peak_list_all_channels.append(r_peak_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RR signal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RR_analysis(rpeaks):\n",
    "    peak_distances = np.diff(rpeaks)\n",
    "    \n",
    "    # stastitical analysis on rr intervals\n",
    "    mean_RR = np.mean(peak_distances)\n",
    "    std_RR = np.std(peak_distances)\n",
    "\n",
    "    #RMSSD\n",
    "    # computes differences between successive RR intervals for RMSSD\n",
    "    diff_RR_intervals = np.diff(peak_distances)\n",
    "    \n",
    "    RMSSD_RR = np.sqrt(np.mean(diff_RR_intervals**2))\n",
    "    \n",
    "    #pNN50\n",
    "    # the number of successive RR intervals that differ by more than 50 ms \n",
    "    NN50 = np.sum(np.abs(diff_RR_intervals) > 50)\n",
    "    # divide by total number of RR intervals\n",
    "    pNN50 = (NN50 / len(peak_distances)) * 100\n",
    "    \n",
    "    return mean_RR, std_RR, RMSSD_RR, pNN50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_means = np.zeros(shape = (no_channels, no_patients))\n",
    "rr_stds = np.zeros(shape = (no_channels, no_patients))\n",
    "rr_RMSSD = np.zeros(shape = (no_channels, no_patients))\n",
    "rr_pNN50s = np.zeros(shape = (no_channels, no_patients))\n",
    "hrs = np.zeros(shape=(no_channels, no_patients))\n",
    "\n",
    "for j in range(0, no_channels):\n",
    "    for i, signal in enumerate(denoised_signals):\n",
    "        peaks = r_peak_list_all_channels[i][j]\n",
    "\n",
    "        rr_mean, rr_std, rr_rmssd, rr_pNN50 = RR_analysis(peaks)\n",
    "    \n",
    "        rr_means[j][i] = rr_mean\n",
    "        rr_stds[j][i] = rr_std\n",
    "        rr_RMSSD[j][i] = rr_rmssd\n",
    "        rr_pNN50s[j][i] = rr_pNN50\n",
    "    \n",
    "        nn_hr = td.hr_parameters(rpeaks=peaks)['hr_mean']\n",
    "        hrs[j][i] = nn_hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physiological measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moments(signal):\n",
    "    mean = np.mean(signal)\n",
    "    std = np.std(signal)\n",
    "    skew_ecg = skew(signal)\n",
    "    kurtosis_ecg = kurtosis(signal)\n",
    "    return mean, std, skew_ecg, kurtosis_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.zeros(shape = (no_channels, no_patients))\n",
    "stds = np.zeros(shape = (no_channels, no_patients))\n",
    "skews = np.zeros(shape = (no_channels, no_patients))\n",
    "kurtosiss = np.zeros(shape = (no_channels, no_patients))\n",
    "\n",
    "\n",
    "for j in range(0, no_channels):\n",
    "    for i, signal in enumerate(denoised_signals):\n",
    "\n",
    "        mean, std, ecg_skew, ecg_kurtosis = get_moments(signal[j])\n",
    "    \n",
    "        means[j][i] = mean\n",
    "        stds[j][i] = std\n",
    "        skews[j][i] = ecg_skew\n",
    "        kurtosiss[j][i] = ecg_kurtosis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_bands(signal):\n",
    "    fs = 1000 #Hz\n",
    "    fs_interpolate = 3 #Hz\n",
    "    \n",
    "    # define frequency bands\n",
    "    lf_band = (0.04, 0.15)\n",
    "    hf_band = (0.15, 0.40)\n",
    "    \n",
    "    peaks, _ = find_peaks(signal, distance=600)\n",
    "    rr_intervals = np.diff(peaks)/fs # RR intervals in seconds, fs is the sampling frequency of the original signal\n",
    "    \n",
    "    # time points of the RR intervals\n",
    "    rr_times = np.cumsum(rr_intervals)\n",
    "    rr_times = np.insert(rr_times, 0, 0)  # add time zero at the beginning\n",
    "\n",
    "    # Interpolation\n",
    "    interpolated_time = np.arange(0, rr_times[-2], 1/fs_interpolate)  # Interpolated time vector\n",
    "    interpolated_rr = interp1d(rr_times[:-1], rr_intervals, kind='cubic')(interpolated_time)\n",
    "\n",
    "    #welch spectrum\n",
    "    f, psd = welch(interpolated_rr, fs=fs_interpolate, nperseg=128)\n",
    "    \n",
    "    # Integrate the power spectral density over the frequency bands\n",
    "    lf_power = np.trapz(psd[(f >= lf_band[0]) & (f <= lf_band[1])], f[(f >= lf_band[0]) & (f <= lf_band[1])])\n",
    "    hf_power = np.trapz(psd[(f >= hf_band[0]) & (f <= hf_band[1])], f[(f >= hf_band[0]) & (f <= hf_band[1])])\n",
    "    \n",
    "    return lf_power, hf_power, lf_power/hf_power\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = np.zeros(shape = (no_channels, no_patients))\n",
    "hfs = np.zeros(shape = (no_channels, no_patients))\n",
    "ratios = np.zeros(shape = (no_channels, no_patients))\n",
    "for j in range(0, no_channels):\n",
    "    for i, signal in enumerate(denoised_signals):\n",
    "        lf, hf, ratio = power_bands(signal[j])\n",
    "        lfs[j][i] = lf\n",
    "        hfs[j][i] = hf\n",
    "        ratios[j][i] = ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poincare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_poincare_sd(sig, remove_outliers=False):\n",
    "    #get rr intervals\n",
    "    rr_intervals = get_rri(sig)\n",
    "    \n",
    "    if remove_outliers:\n",
    "        rr_intervals = rr_intervals[outliers_indices_z_score(rr_intervals)]\n",
    "        \n",
    "    #separating into subsequent coordinates for Poincaré plot\n",
    "    rr_n = rr_intervals[:-1]\n",
    "    rr_n1 = rr_intervals[1:]\n",
    "    \n",
    "    #calculating SD1, perpendicular to y=x\n",
    "    diff_rr = np.array(rr_n) - np.array(rr_n1)\n",
    "    sd1 = np.sqrt(np.var(diff_rr/np.sqrt(2)))\n",
    "    \n",
    "    # calculating SD2, along y=x\n",
    "    sum_rr = rr_n + rr_n1\n",
    "    sd2 = np.sqrt(np.var(sum_rr/np.sqrt(2)))\n",
    "    \n",
    "    # calculating ratio\n",
    "    sd_ratio = sd2/sd1\n",
    "   \n",
    "    #counting intervals outside SD1 and SD2\n",
    "    count_outside_sd1 = np.sum(np.abs(diff_rr / np.sqrt(2)) > sd1)\n",
    "    count_outside_sd2 = np.sum(np.abs(sum_rr / np.sqrt(2)) > sd2)\n",
    "\n",
    "    out = count_outside_sd1 + count_outside_sd2\n",
    "    return sd1, sd2, sd_ratio, count_outside_sd1, count_outside_sd2, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd1s = np.zeros(shape = (no_channels, no_patients))\n",
    "sd2s = np.zeros(shape = (no_channels, no_patients))\n",
    "sd_ratios = np.zeros(shape=(no_channels, no_patients))\n",
    "out_sd1s = np.zeros(shape=(no_channels, no_patients))\n",
    "out_sd2s = np.zeros(shape=(no_channels,no_patients))\n",
    "n_out = np.zeros(shape = (no_channels, no_patients))\n",
    "for j in range(0, no_channels):\n",
    "    for i, signal in enumerate(denoised_signals):\n",
    "        sd1, sd2, sd_ratio, out_sd1, out_sd2, out = calculate_poincare_sd(signal[j], remove_outliers=True)\n",
    "        sd1s[j][i] = sd1\n",
    "        sd2s[j][i] = sd2\n",
    "        sd_ratios[j][i] = sd_ratio\n",
    "        out_sd1s[j][i] = out_sd1\n",
    "        out_sd2s[j][i] = out_sd2\n",
    "        n_out[j][i] = out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shannon Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shannon_entropy(rr_intervals, num_bins=10):\n",
    "    # discretize RR intervals into bins and calculate probabilities\n",
    "    hist, bin_edges = np.histogram(rr_intervals, bins=num_bins, density=True)\n",
    "    \n",
    "    probabilities = hist / np.sum(hist)\n",
    "    \n",
    "    # Calculate Shannon Entropy using equation\n",
    "    shannon_entropy = -np.sum(probabilities * np.log2(probabilities + 1e-12))  # adding a small value to avoid log(0)\n",
    "    \n",
    "    return shannon_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "shannon_ens = np.zeros(shape = (no_channels, no_patients))\n",
    "for j in range(0, no_channels):\n",
    "    for i, signal in enumerate(denoised_signals):\n",
    "        shannon_en = calculate_shannon_entropy(signal[j])\n",
    "        shannon_ens[j][i] = shannon_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Parameter Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create dictionary with parameters\n",
    "params = {}\n",
    "\n",
    "#time components\n",
    "params['rr_mean'] = rr_means\n",
    "params['rr_std'] = rr_stds\n",
    "params['RMSSD'] = rr_RMSSD\n",
    "params['pNN50'] = rr_pNN50s\n",
    "params['mean'] = means\n",
    "params['std'] = stds\n",
    "params['skews'] = skews\n",
    "params['kurtosis'] = kurtosiss\n",
    "#frequency components\n",
    "params['hf'] = hfs\n",
    "params['lf'] = lfs\n",
    "params['power_ratio'] = ratios\n",
    "#nonlinear components\n",
    "params['shannon_en'] = shannon_ens\n",
    "params['sd_ratio'] = sd_ratios\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params['sd_ratio'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
