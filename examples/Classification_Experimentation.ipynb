{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook exists to experiment with different methods for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 549/549 [00:40<00:00, 13.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 196/196 [00:03<00:00, 55.17it/s]\n"
     ]
    }
   ],
   "source": [
    "%run \"Feature_Selection.ipynb\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sd_ratio'])\n"
     ]
    }
   ],
   "source": [
    "removed_params = ['rr_std', 'RMSSD', 'pNN50', 'mean', 'lf', 'hf', 'skews', 'rr_mean', 'power_ratio', 'std', 'kurtosis', 'shannon_en'] #convert to a set?\n",
    "\n",
    "selected_params = {}\n",
    "for key in params.keys():\n",
    "    if key not in removed_params:\n",
    "        selected_params[key] = params[key]\n",
    "print(selected_params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "health_state = np.array(allowed_patients.get_diagnoses())\n",
    "\n",
    "encoded_health_state = [1 if label == 'Unhealthy' else -1 for label in health_state]\n",
    "\n",
    "print(len(health_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_accuracy(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    balanced accuracy....\n",
    "    \"\"\"\n",
    "    num_healthy_true = np.sum([x=='Healthy' for x in y_test])\n",
    "    num_unhealthy_true = len(y_test) - num_healthy_true\n",
    "    count_healthy_accurate = 0\n",
    "    count_unhealthy_accurate = 0\n",
    "    for i in range(0, len(y_test)):\n",
    "        if y_pred[i] == y_test[i] == 'Unhealthy':\n",
    "            count_unhealthy_accurate +=1\n",
    "        elif y_pred[i] == y_test[i] == 'Healthy':\n",
    "            count_healthy_accurate +=1\n",
    "    healthy_percentage = count_healthy_accurate/num_healthy_true\n",
    "    unhealthy_percentage = count_unhealthy_accurate/num_unhealthy_true\n",
    "    balanced_accuracy = (healthy_percentage + unhealthy_percentage) * 0.5\n",
    "    return balanced_accuracy\n",
    "\n",
    "def get_specificity(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    true negative rate\n",
    "    \"\"\"\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    for i in range(0, len(y_test)):\n",
    "        if y_pred[i] == y_test[i] == 'Healthy':\n",
    "            true_negative += 1\n",
    "        elif y_pred[i] != y_test[i] and y_test[i] == 'Healthy':\n",
    "            false_positive += 1\n",
    "    \n",
    "    return true_negative / (true_negative+false_positive)\n",
    "            \n",
    "def get_f1_score(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    balance between precision and recall\n",
    "    \"\"\"\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    for i in range(0, len(y_test)):\n",
    "        if y_pred[i] == y_test[i] == 'Unhealthy':\n",
    "            true_positive += 1\n",
    "        elif y_pred[i] != y_test[i] and y_test[i] == 'Healthy':\n",
    "            false_positive += 1\n",
    "        elif y_pred[i] != y_test[i] and y_test[i] == 'Unhealthy':\n",
    "            false_negative += 1\n",
    "    return (2*true_positive)/(2*true_positive+false_positive+false_negative)\n",
    "\n",
    "\n",
    "def get_av_confusion_matrix(y_test, y_pred):\n",
    "    av_confusion_mat = np.zeros(shape = (len(y_test), 2, 2))\n",
    "    for i in range(0, len(y_test)):\n",
    "        av_confusion_mat[i] = confusion_matrix(y_test[i], y_pred[i])\n",
    "    return np.mean(av_confusion_mat, axis=0)\n",
    "\n",
    "def scoring_function(model, X, y):\n",
    "    \"\"\"\n",
    "    change to incorporate balanced accuracy \n",
    "    \"\"\"\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    y_test = y\n",
    "    balanced_acc = get_balanced_accuracy(y_test, y_pred)\n",
    "    specificity = get_specificity(y_test, y_pred)\n",
    "    f1 = get_f1_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    return f1*0.7 + balanced_acc*0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def convert_dict_to_array(selected_params):\n",
    "    no_features = len(selected_params)\n",
    "    selected_params_array = np.zeros((no_channels, no_patients, no_features))\n",
    "    \n",
    "    for j in range(0, no_channels):\n",
    "        for i, values in enumerate(selected_params.values()):\n",
    "            selected_params_array[j][:, i] = values[j]\n",
    "    return selected_params_array, no_features\n",
    "\n",
    "        \n",
    "selected_params_array, no_features = convert_dict_to_array(selected_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1776776  0.8223224 ]\n",
      " [0.32762719 0.67237281]\n",
      " [0.36315422 0.63684578]\n",
      " [0.19114033 0.80885967]\n",
      " [0.13890857 0.86109143]\n",
      " [0.13595551 0.86404449]\n",
      " [0.15702067 0.84297933]\n",
      " [0.35192144 0.64807856]\n",
      " [0.20533057 0.79466943]\n",
      " [0.18178267 0.81821733]\n",
      " [0.36193017 0.63806983]\n",
      " [0.12757749 0.87242251]\n",
      " [0.15992855 0.84007145]\n",
      " [0.14491477 0.85508523]\n",
      " [0.25726742 0.74273258]\n",
      " [0.22060341 0.77939659]\n",
      " [0.264638   0.735362  ]\n",
      " [0.10923593 0.89076407]\n",
      " [0.23614693 0.76385307]\n",
      " [0.10808522 0.89191478]\n",
      " [0.21012091 0.78987909]\n",
      " [0.1359941  0.8640059 ]\n",
      " [0.30467727 0.69532273]\n",
      " [0.14831865 0.85168135]\n",
      " [0.18625672 0.81374328]\n",
      " [0.31558503 0.68441497]\n",
      " [0.09878978 0.90121022]\n",
      " [0.35577334 0.64422666]\n",
      " [0.12622218 0.87377782]\n",
      " [0.24710084 0.75289916]\n",
      " [0.18569333 0.81430667]\n",
      " [0.36547052 0.63452948]\n",
      " [0.35267362 0.64732638]\n",
      " [0.13817142 0.86182858]\n",
      " [0.15748661 0.84251339]\n",
      " [0.13609207 0.86390793]\n",
      " [0.13699357 0.86300643]\n",
      " [0.13971907 0.86028093]\n",
      " [0.18450037 0.81549963]\n",
      " [0.24258428 0.75741572]\n",
      " [0.18849637 0.81150363]\n",
      " [0.19585161 0.80414839]\n",
      " [0.14813202 0.85186798]\n",
      " [0.14446115 0.85553885]\n",
      " [0.1468016  0.8531984 ]\n",
      " [0.36315362 0.63684638]\n",
      " [0.13794747 0.86205253]\n",
      " [0.35498796 0.64501204]\n",
      " [0.21118826 0.78881174]\n",
      " [0.26588435 0.73411565]\n",
      " [0.36552216 0.63447784]\n",
      " [0.16536316 0.83463684]\n",
      " [0.27023125 0.72976875]\n",
      " [0.13665101 0.86334899]\n",
      " [0.19381955 0.80618045]\n",
      " [0.26123405 0.73876595]\n",
      " [0.18178941 0.81821059]\n",
      " [0.16188586 0.83811414]\n",
      " [0.16040733 0.83959267]]\n",
      "['Unhealthy' 'Healthy' 'Healthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Healthy' 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Healthy' 'Unhealthy'\n",
      " 'Healthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Healthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Healthy'\n",
      " 'Unhealthy' 'Healthy' 'Healthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Healthy'\n",
      " 'Unhealthy' 'Healthy' 'Healthy' 'Unhealthy' 'Healthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Healthy' 'Unhealthy' 'Unhealthy' 'Unhealthy']\n",
      "0.22627737226277372\n",
      "['Unhealthy', 'Healthy', 'Healthy', 'Unhealthy', 'Unhealthy', 'Unhealthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Unhealthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Unhealthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Healthy', 'Healthy', 'Unhealthy', 'Unhealthy', 'Unhealthy', 'Unhealthy', 'Unhealthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Unhealthy', 'Unhealthy', 'Unhealthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Healthy', 'Healthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Unhealthy', 'Healthy', 'Unhealthy', 'Unhealthy', 'Unhealthy']\n",
      "Accuracy: 0.6779661016949152\n",
      "balanced accuracy: 0.6279264214046822\n",
      "13\n",
      "['Healthy' 'Unhealthy' 'Healthy' 'Healthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Healthy' 'Healthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Healthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Healthy' 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Healthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'] ['Unhealthy' 'Healthy' 'Healthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Healthy' 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Healthy' 'Unhealthy'\n",
      " 'Healthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Healthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Healthy'\n",
      " 'Unhealthy' 'Healthy' 'Healthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Healthy' 'Unhealthy' 'Healthy'\n",
      " 'Unhealthy' 'Healthy' 'Healthy' 'Unhealthy' 'Healthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Healthy' 'Unhealthy' 'Unhealthy' 'Unhealthy']\n"
     ]
    }
   ],
   "source": [
    "#splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_params_array[0], health_state, test_size=0.3, stratify=health_state)\n",
    "\n",
    "#init and train model, using radial basis functions\n",
    "svm_model = SVC(kernel='rbf', gamma='scale', probability=True, class_weight = 'balanced')  #'scale' normalises data, prevents overfitting\n",
    "#probability = True allows calculation of probabilities through 5-fold CV\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "#predicting probabilities\n",
    "probabilities = svm_model.predict_proba(X_test)\n",
    "print(probabilities)\n",
    "\n",
    "\n",
    "#predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "percentage_healthy = np.sum([x=='Healthy' for x in y_train])/len(y_train)\n",
    "print(percentage_healthy)\n",
    "\n",
    "manual_predict = []\n",
    "for i in range(0, len(probabilities)):\n",
    "    if probabilities[i][0] > percentage_healthy:\n",
    "        manual_predict.append('Healthy')\n",
    "    else:\n",
    "        manual_predict.append('Unhealthy')\n",
    "\n",
    "print(manual_predict)\n",
    "    \n",
    "#evaluating accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "balanced_accuracy = get_balanced_accuracy(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print('balanced accuracy:', balanced_accuracy)\n",
    "\n",
    "print(np.sum([x=='Healthy' for x in y_test]))\n",
    "print(y_test, y_pred)\n",
    "\n",
    "#view a classification report\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning\n",
    "- c is inversely proportional to l2 regularisation parameter\n",
    "- gamma determines scaling of features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "#recall needs encoded_health_state\n",
    "#splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_params_array, health_state, test_size=0.3, stratify=health_state)\n",
    "\n",
    "# define hyperparameter grid to test\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "#initialise\n",
    "svc = SVC(class_weight='balanced')\n",
    "\n",
    "# perform grid search\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, scoring=scoring_function)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# train with best parameters\n",
    "best_svc = grid_search.best_estimator_\n",
    "best_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "y_pred = best_svc.predict(X_test)\n",
    "\n",
    "#evaluating accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "balanced_accuracy = get_balanced_accuracy(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print('balanced accuracy:', balanced_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified k-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to weight the train and test sets to cope with difference with numbers of healthy and unhealthy, stratified k-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits = 3 #3 fold validation\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True) #can do repeated skf for better validation\n",
    "\n",
    "\n",
    "accuracies=[]\n",
    "balanced_accuracies=[]\n",
    "y_pred_list = []\n",
    "y_test_list=[]\n",
    "for train_index, test_index in skf.split(selected_params_array, health_state):\n",
    "    #getting test and train data sets\n",
    "    X_train, X_test = selected_params_array[train_index], selected_params_array[test_index]\n",
    "    y_train, y_test = health_state[train_index], health_state[test_index]\n",
    "    \n",
    "    y_test_list.append(y_test)\n",
    "    #training model with tuned hyperparameters\n",
    "    tuned_svc = grid_search.best_estimator_\n",
    "    tuned_svc.fit(X_train, y_train)\n",
    "    \n",
    "    #evaluating model\n",
    "    y_pred = tuned_svc.predict(X_test)\n",
    "    y_pred_list.append(y_pred)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    balanced_accuracies.append((get_balanced_accuracy(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracies)\n",
    "print(balanced_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(balanced_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_list[2], y_test_list[2])\n",
    "print(confusion_matrix(y_pred_list[2], y_test_list[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_list[1], y_pred_list[1]))\n",
    "print(get_specificity(y_test_list[1], y_pred_list[1]))\n",
    "print(get_av_confusion_matrix(y_test_list, y_pred_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
