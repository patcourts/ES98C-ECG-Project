{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook exists too experiment with the different methods seen to perform feature selection. Methods include:\n",
    "- Statistical Measures\n",
    "- PCA\n",
    "- Wrapper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 549/549 [00:28<00:00, 19.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 229/229 [00:02<00:00, 93.99it/s]\n"
     ]
    }
   ],
   "source": [
    "%run \"Parameter_Estimation.ipynb\" #allowing access to parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_state = allowed_patients.get_diagnoses()\n",
    "\n",
    "encoded_health_state = [True if label == 'Unhealthy' else False for label in health_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### investigating correlation \n",
    "- currently using peason r (pmcc)\n",
    "- investigate Wilson Cox??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter rr_mean and parameter rr_std are significantly correlated, p = 0.039489188328994965, corr = 0.13617674637503555\n",
      "parameter rr_std and parameter RMSSD are significantly correlated, p = 1.2749464219281778e-144, corr = 0.9719160832903705\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import itertools\n",
    "\n",
    "\n",
    "for key1, key2 in itertools.combinations(params.keys(), 2):\n",
    "    corr, p_value = pearsonr(params[key1], params[key2])\n",
    "    if p_value < 0.05:\n",
    "        print(f\"parameter {key1} and parameter {key2} are significantly correlated, p = {p_value}, corr = {corr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter rr_mean and parameter rr_std are significantly correlated, p = 2.5423782627801044e-39, stat = 0.0\n",
      "parameter rr_mean and parameter RMSSD are significantly correlated, p = 2.5423782627801044e-39, stat = 0.0\n",
      "parameter rr_std and parameter RMSSD are significantly correlated, p = 7.182851169858021e-10, stat = 6983.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "for key1, key2 in itertools.combinations(params.keys(), 2):\n",
    "    stat, p_value = wilcoxon(params[key1], params[key2])\n",
    "    if p_value < 0.05:\n",
    "        print(f\"parameter {key1} and parameter {key2} are significantly correlated, p = {p_value}, stat = {stat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare above results with papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "- loses the knowledge of features, less intuitive\n",
    "- will experiment with it anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array\n",
    "X = np.zeros((no_patients, 4))#need no. samples as rows, no. features as columns for machine learning analysis\n",
    "\n",
    "# Populate the array with values from the dictionary\n",
    "X[:, 0] = params['rr_mean']\n",
    "X[:, 1] = params['rr_std']\n",
    "X[:, 2] = params['RMSSD']\n",
    "#X[:, 3] = params['pNN50']\n",
    "    \n",
    "#standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#set desired number of principle components\n",
    "num_components = 2\n",
    "\n",
    "#using sklearn PCA\n",
    "pca = PCA(n_components=num_components)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy' 'Unhealthy'\n",
      " 'Unhealthy' 'Unhealthy' 'Unhealthy']\n",
      "Accuracy: 0.8405797101449275\n"
     ]
    }
   ],
   "source": [
    "#using principle components to do ML\n",
    "\n",
    "#splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, health_state, test_size=0.3)\n",
    "\n",
    "#init and train model, using radial basis functions\n",
    "svm_classifier = SVC(kernel='rbf', gamma='scale')  #'scale' normalises data, prevents overfitting\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "#evaluating accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper Methods:\n",
    "\n",
    "These methods do feature selection whilst using the model\n",
    "\n",
    " - Forward Selection: Features are sequentially added to the model, starting with an empty set and adding the feature that improves model performance the most at each step.\n",
    " - Backward Elimination: Features are sequentially removed from the model, starting with the full set of features and removing the feature that decreases model performance the least at each step.\n",
    " - Recursive Feature Elimination (RFE): Features are recursively pruned based on the importance assigned to them by the model. Less important features are eliminated iteratively until the desired number of features is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3ddf2dfa8d23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#splitting data into test and train sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhealth_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#initialise SVM -- have to use a linear kernel??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# initializing parameter array\n",
    "X = np.zeros((no_patients, 3))#need no. samples as rows, no. features as columns for machine learning analysis\n",
    "X[:, 0] = params['rr_mean']\n",
    "X[:, 1] = params['rr_std']\n",
    "X[:, 2] = params['RMSSD']\n",
    "#X[:, 3] = params['pNN50']\n",
    "\n",
    "#splitting data into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, health_state, test_size=0.3)\n",
    "\n",
    "#initialise SVM -- have to use a linear kernel??\n",
    "svm = SVC(kernel=\"linear\")\n",
    "\n",
    "#initialize RFE with the SVM model and desired number of feauters\n",
    "rfe = RFE(estimator=svm, n_features_to_select=1)\n",
    "\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Selected features:\", rfe.support_)\n",
    "print(\"Feature ranking:\", rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataset to include only the selected features\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# train the SVM on the selected features\n",
    "svm.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm.predict(X_test_rfe)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy with selected features:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward/Backward Elimination\n",
    "\n",
    "May be slower than RFE but does not need to have coefficients i.e. a linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector \n",
    "\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "SFS_forward = SequentialFeatureSelector(estimator=svm_rbf, tol = 5)\n",
    "\n",
    "SFS_forward.fit(X_train, y_train)\n",
    "\n",
    "SFS_forward.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFS_backward = SequentialFeatureSelector(estimator=svm_rbf, tol=-5, direction='backward')\n",
    "\n",
    "SFS_backward.fit(X_train, y_train)\n",
    "\n",
    "SFS_forward.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these agree only first one should be kept but disagrees with RFE???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded Methods:\n",
    "\n",
    "Also done whilst using the model\n",
    "\n",
    "- Regularization: Techniques like LASSO (L1 regularization) and Ridge (L2 regularization) penalize the magnitude of feature coefficients, forcing less important features to have coefficients close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LASSO/Ridge Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#changing health_state to binary for use in regression\n",
    "binary_health_state = [1 if label == 'Unhealthy' else 0 for label in health_state]\n",
    "\n",
    "#splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, binary_health_state, test_size=0.3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "#create and fit regression models\n",
    "lasso_alpha = 0.1  # Regularization strength (hyperparameter)\n",
    "lasso = Lasso(alpha=lasso_alpha)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "ridge_alpha = 0.1 \n",
    "ridge = Ridge(alpha=ridge_alpha)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "#use the trained models for prediction\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "y_pred_ridge = ridge.predict(X_test_scaled)\n",
    "y_pred_lasso = lasso.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
